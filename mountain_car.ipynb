{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning of actions:\n",
    "- action = 0 - go left \\\n",
    "- action = 1 - stand still \\\n",
    "- action = 2 - go right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56521661  0.00132115] -1.0 False {}\n",
      "[-0.56258414  0.00263248] -1.0 False {}\n",
      "[-0.55865994  0.0039242 ] -1.0 False {}\n",
      "[-0.55347326  0.00518667] -1.0 False {}\n",
      "[-0.54706283  0.00641043] -1.0 False {}\n",
      "[-0.53947656  0.00758627] -1.0 False {}\n",
      "[-0.53077125  0.00870531] -1.0 False {}\n",
      "[-0.52101216  0.0097591 ] -1.0 False {}\n",
      "[-0.51027246  0.0107397 ] -1.0 False {}\n",
      "[-0.49863269  0.01163978] -1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "obs = env.reset()\n",
    "\n",
    "for t in range(10):\n",
    "    env.render()\n",
    "    # observation, reward, done, info = env.step(env.action_space.sample())\n",
    "    obs, reward, done, info = env.step(2)\n",
    "    time.sleep(0.01)\n",
    "    print(obs, reward, done, info)\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 51\n",
      "Trainable params: 51\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Building the policy network ###\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_shape = (2, ), activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "\n",
    "opt = Adam(learning_rate = learning_rate)\n",
    "model.compile(optimizer = opt, loss = 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forward pass of the policy network (one fully-connected layer) ###\n",
    "def forward_pass(x, w, b):\n",
    "    return np.dot(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize network ### \n",
    "w = np.random.normal(size = (num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_perceptron:\n",
    "    \n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.w = np.random.normal(size = (num_inputs, num_outputs))\n",
    "        self.b = np.random.normal(size = num_outputs)\n",
    "        \n",
    "    # Using softmax as the activation function!\n",
    "    def forward_pass(self, x):\n",
    "        h = np.dot(x, self.w) + self.b\n",
    "        return np.exp(h) / np.sum(np.exp(h))\n",
    "    \n",
    "    def get_w(self):\n",
    "        return self.w\n",
    "    \n",
    "    def get_b(self):\n",
    "        return self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "[0.98596315 0.00650538 0.00753146]\n"
     ]
    }
   ],
   "source": [
    "model = simple_perceptron(2, 3)\n",
    "x = np.array([1, 2])\n",
    "print(x.shape)\n",
    "y = model.forward_pass(x)\n",
    "print(y)\n",
    "#print(model.get_w().shape)\n",
    "#print(model.get_b().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "obs =  [[-0.47847833  0.00948019]] (1, 2)\n",
      "[[0.40123922 0.29580644 0.30295435]]\n"
     ]
    }
   ],
   "source": [
    "### Trying to make some initial predictions to make sure dimensions etc are as expected ###\n",
    "print(obs.shape)\n",
    "obs = np.reshape(obs, (1, 2))\n",
    "#t = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "#print(t, t.shape)\n",
    "print('obs = ', obs, obs.shape)\n",
    "pred = model.predict(obs)\n",
    "#pred = model.predict(t)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40123922 0.29580644 0.30295435]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]] <class 'numpy.ndarray'> (1, 1)\n"
     ]
    }
   ],
   "source": [
    "samples = tf.random.categorical(tf.math.log(pred), 1)\n",
    "samples = np.array(samples)\n",
    "print(samples, type(samples), samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # Number of episodes to run before updating the network\n",
    "num_epochs = 1\n",
    "t_max = 100 # Number of time-steps before the episode is automatically terminated\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "\n",
    "def train_one_epoch(policy_network, num_episodes):\n",
    "    \n",
    "    batch_obs = []\n",
    "    batch_rets = []\n",
    "    batch_lens = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "    \n",
    "        obs = env.reset()             # Initial observation\n",
    "        obs = np.reshape(obs, (1, 2)) # Reshape to make it fit the network\n",
    "        \n",
    "        ep_obs = []\n",
    "        ep_ret = 0\n",
    "    \n",
    "        for t in range(t_max):\n",
    "\n",
    "            env.render()\n",
    "            time.sleep(0.01) # For visualizing the episode\n",
    "            \n",
    "            pred = policy_network.predict(obs)                # Making a prediction from the policy network, remember that the last layer is a softmax layer\n",
    "            act = tf.random.categorical(tf.math.log(pred), 1) # Sample an action based on the probabilities given from the softmax layer\n",
    "            act = int(np.array(act))\n",
    "            #print('act = ', act)\n",
    "            \n",
    "            obs, reward, done, info = env.step(act)\n",
    "            #print(obs, reward, done, info)\n",
    "            ep_ret += reward\n",
    "            ep_obs.append(obs)\n",
    "            obs = np.reshape(obs, (1, 2))\n",
    "            \n",
    "            \n",
    "            # If the agent has reached its goal\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        env.close()\n",
    "        \n",
    "        batch_obs.append(ep_obs)\n",
    "        batch_rets.append(ep_ret)\n",
    "        batch_lens.append(t+1)\n",
    "        \n",
    "    return batch_obs, batch_rets, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_obs, batch_rets, batch_lens = train_one_epoch(policy_network = model, num_episodes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_obs =  [[array([-0.49846256, -0.0011973 ]), array([-0.4998482 , -0.00138564]), array([-0.50241182, -0.00256362]), array([-0.50613423, -0.00372241]), array([-0.51098757, -0.00485334]), array([-0.51693547, -0.0059479 ]), array([-0.52293334, -0.00599787]), array([-0.5289362 , -0.00600286]), array([-0.53389903, -0.00496283]), array([-0.53978462, -0.00588559]), array([-0.54554887, -0.00576425]), array([-0.55114861, -0.00559974]), array([-0.55554196, -0.00439335]), array([-0.5606961 , -0.00515414]), array([-0.56657259, -0.00587649]), array([-0.57312766, -0.00655508]), array([-0.57931264, -0.00618497]), array([-0.5860817 , -0.00676906]), array([-0.59138488, -0.00530318]), array([-0.59618316, -0.00479828]), array([-0.60144136, -0.00525819]), array([-0.60612102, -0.00467966]), array([-0.60918807, -0.00306705]), array([-0.61262023, -0.00343216]), array([-0.61439264, -0.00177241]), array([-6.14492481e-01, -9.98429354e-05]), array([-0.61291904,  0.00157344]), array([-0.61168368,  0.00123536]), array([-0.60879535,  0.00288833]), array([-0.60527498,  0.00352037]), array([-0.60214814,  0.00312683]), array([-0.59843763,  0.00371052]), array([-0.59517053,  0.0032671 ]), array([-0.59137075,  0.00379978]), array([-0.58706618,  0.00430457]), array([-0.58328847,  0.00377771]), array([-0.57906548,  0.00422299]), array([-0.57542841,  0.00363707]), array([-0.57040418,  0.00502423]), array([-0.56403006,  0.00637412]), array([-0.55635345,  0.00767661]), array([-0.54943157,  0.00692188]), array([-0.54331615,  0.00611543]), array([-0.53705293,  0.00626322]), array([-0.53168883,  0.0053641 ]), array([-0.52626406,  0.00542477]), array([-0.5208193 ,  0.00544476]), array([-0.51639538,  0.00442391]), array([-0.51302549,  0.00336989]), array([-0.50873489,  0.00429061]), array([-0.50555572,  0.00317916]), array([-0.50351181,  0.00204391]), array([-0.50161847,  0.00189335]), array([-0.49988986,  0.00172861]), array([-0.49933891,  0.00055095]), array([-4.98969753e-01,  3.69157394e-04]), array([-0.49978515, -0.00081539]), array([-0.50077899, -0.00099384]), array([-5.00943845e-01, -1.64857340e-04]), array([-0.50027848,  0.00066536]), array([-0.49878788,  0.0014906 ]), array([-0.49748319,  0.00130469]), array([-0.49637416,  0.00110903]), array([-4.96469097e-01, -9.49322377e-05]), array([-0.49776728, -0.00129818]), array([-4.9825900e-01, -4.9172265e-04]), array([-0.49894059, -0.00068159]), array([-4.98806943e-01,  1.33644238e-04]), array([-4.98859067e-01, -5.21231239e-05]), array([-4.99096567e-01, -2.37500641e-04]), array([-0.49851767,  0.0005789 ]), array([-0.4971267 ,  0.00139097]), array([-0.49593407,  0.00119264]), array([-4.95948678e-01, -1.46117448e-05]), array([-0.49717043, -0.00122175]), array([-0.49859018, -0.00141975]), array([-0.50119733, -0.00260714]), array([-0.50497235, -0.00377503]), array([-0.50888701, -0.00391465]), array([-0.51391196, -0.00502496]), array([-0.51800956, -0.0040976 ]), array([-0.52214907, -0.00413951]), array([-0.52629946, -0.00415039]), array([-0.53142959, -0.00513013]), array([-0.536501  , -0.00507141]), array([-0.54247566, -0.00597466]), array([-0.54730882, -0.00483316]), array([-0.55096431, -0.00365549]), array([-0.55441478, -0.00345048]), array([-0.55763447, -0.00321968]), array([-0.56059933, -0.00296486]), array([-0.56428726, -0.00368793]), array([-0.56667078, -0.00238352]), array([-0.56973215, -0.00306138]), array([-0.57344863, -0.00371648]), array([-0.57679263, -0.003344  ]), array([-0.57873937, -0.00194674]), array([-0.58027443, -0.00153507]), array([-0.58238648, -0.00211204]), array([-0.5840599 , -0.00167342])], [array([-0.47618397,  0.00065042]), array([-4.75887969e-01,  2.96003464e-04]), array([-4.75948576e-01, -6.06070316e-05]), array([-0.47736534, -0.00141677]), array([-0.48012775, -0.00276241]), array([-0.48421527, -0.00408752]), array([-0.48759747, -0.00338221]), array([-0.49024917, -0.00265169]), array([-0.49415056, -0.0039014 ]), array([-0.49927253, -0.00512197]), array([-0.50557679, -0.00630426]), array([-0.51301614, -0.00743936]), array([-0.52053486, -0.00751871]), array([-0.52907655, -0.00854169]), array([-0.53757716, -0.00850061]), array([-0.54497296, -0.0073958 ]), array([-0.55320856, -0.00823561]), array([-0.56122239, -0.00801382]), array([-0.56795463, -0.00673225]), array([-0.57335519, -0.00540056]), array([-0.57938396, -0.00602877]), array([-0.58399629, -0.00461233]), array([-0.58915811, -0.00516182]), array([-0.5948314 , -0.00567329]), array([-0.60097451, -0.0061431 ]), array([-0.60554249, -0.00456798]), array([-0.60950207, -0.00395958]), array([-0.61182448, -0.00232241]), array([-0.6144929 , -0.00266842]), array([-0.61748802, -0.00299513]), array([-0.62078826, -0.00330023]), array([-0.62236985, -0.0015816 ]), array([-0.62422146, -0.0018516 ]), array([-0.6253298 , -0.00110834]), array([-0.62468695,  0.00064285]), array([-6.24297510e-01,  3.89442541e-04]), array([-0.62216426,  0.00213325]), array([-0.6203025 ,  0.00186176]), array([-0.61872559,  0.00157691]), array([-0.61644487,  0.00228072]), array([-0.61447678,  0.00196809]), array([-0.61083551,  0.00364127]), array([-0.60654742,  0.0042881 ]), array([-0.6006436 ,  0.00590381]), array([-0.59516709,  0.00547652]), array([-0.59015792,  0.00500916]), array([-0.58465287,  0.00550505]), array([-0.57969248,  0.0049604 ]), array([-0.57431336,  0.00537912]), array([-0.56955535,  0.00475801]), array([-0.56345375,  0.00610159]), array([-0.55605396,  0.0073998 ]), array([-0.54741114,  0.00864282]), array([-0.53758987,  0.00982127]), array([-0.5266637 ,  0.01092617]), array([-0.51671455,  0.00994915]), array([-0.50781702,  0.00889753]), array([-0.49803781,  0.00977921]), array([-0.48945013,  0.00858769]), array([-0.48111811,  0.00833202]), array([-0.47410383,  0.00701428]), array([-0.4664594 ,  0.00764443]), array([-0.46024142,  0.00621798]), array([-0.45349577,  0.00674565]), array([-0.44627202,  0.00722375]), array([-0.43862303,  0.00764899]), array([-0.43260448,  0.00601855]), array([-0.42825995,  0.00434454]), array([-0.42362074,  0.0046392 ]), array([-0.41872018,  0.00490056]), array([-0.4155933 ,  0.00312689]), array([-0.41426235,  0.00133094]), array([-0.41373681,  0.00052555]), array([-4.14020389e-01, -2.83581832e-04]), array([-4.14111087e-01, -9.06972713e-05]), array([-4.14008256e-01,  1.02831123e-04]), array([-0.41471263, -0.00070437]), array([-0.4172192 , -0.00250657]), array([-0.42151014, -0.00429094]), array([-0.42755483, -0.00604469]), array([-0.43530993, -0.0077551 ]), array([-0.44471948, -0.00940955]), array([-0.45471512, -0.00999564]), array([-0.46622371, -0.0115086 ]), array([-0.4771605 , -0.01093679]), array([-0.48844445, -0.01128395]), array([-0.49899157, -0.01054712]), array([-0.50972307, -0.0107315 ]), array([-0.52055861, -0.01083554]), array([-0.53241695, -0.01185834]), array([-0.54320917, -0.01079221]), array([-0.55385439, -0.01064522]), array([-0.56327301, -0.00941862]), array([-0.57239477, -0.00912176]), array([-0.58015186, -0.0077571 ]), array([-0.58748684, -0.00733498]), array([-0.59434559, -0.00685875]), array([-0.60067771, -0.00633212]), array([-0.60743688, -0.00675917]), array([-0.61457387, -0.00713699])]] 2\n",
      "----------\n",
      "batch_rets =  [-100.0, -100.0]\n",
      "batch_lens =  [100, 100]\n"
     ]
    }
   ],
   "source": [
    "print('batch_obs = ', batch_obs, len(batch_obs))\n",
    "print('----------')\n",
    "print('batch_rets = ', batch_rets)\n",
    "print('batch_lens = ', batch_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAIGym",
   "language": "python",
   "name": "openaigym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
